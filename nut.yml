syntax_version: "6"
project_name: tunneleffect
# docker_image: matthieudelaro/caffe-iuf-modif
# docker_image: matthieudelaro/work-on-caffe
container_working_directory: /opt/caffe
docker_image: matthieudelaro/caffe-iuf-python
enable_nvidia_devices: true
environment:
  NUT_VOLUME_MAIN_PATH: /nut/tunneleffect/
  NUT_VOLUME_DATASET_PATH: /nut/tunneleffect/dataset
  # NUT_VOLUME_LOGS_PATH: /nut/tunneleffect/logs
  # NUT_VOLUME_SNAPSHOTS_PATH: /nut/tunneleffect/snapshots
mount:
  main:
  - .
  - /nut/tunneleffect/
  # src:
  # - ./src
  # - /nut/tunneleffect/src

  # caffe:
  # # - ./caffeBVLC
  # # - ./caffeBVLCplus # BVLC plus
  # # - ./caffe # BVLC plus plus (plus, but updated)
  # - ./caffeOld
  # - /opt/caffe
  dataset: # if you store your datasets in another folder, add them this way
  # - ../hyperestimate/dataset
  - ./dataset
  - /dataset
macros:
  tunnel:
    usage: runs the whole training for Tunnel Effect, with all pretraining
    container_working_directory: /nut/tunneleffect/
    actions:
    - export PREFIX=$NUT_VOLUME_MAIN_PATH/logs/`date '+started%y-%m-%d_%Hh%Mm%Ss'`
    - mkdir -p $NUT_VOLUME_MAIN_PATH/snapshots
    - mkdir -p $NUT_VOLUME_MAIN_PATH/logs
    - mkdir -p $PREFIX.data
    - cp -R proto $PREFIX.data/proto
    - cp -R nut.yml $PREFIX.data/
    # USELESS STEP (TESTED with old caffe) - caffe train --solver="proto/solverPretrain.prototxt" > $PREFIX.step000_pretrain.txt 2>&1
      # - caffe train --solver="proto/solverPretrain.prototxt" --snapshot="snapshots/pretraining__iter_2000.solverstate"  # just to go on in screen during the night
      # accu from 1.1% to 1.5% after 2000 iterations
      # 5000: 1.3
      # 10000: 11
      # 16000: 22
      # 20000: 25
      # 30000: 31
      # 40000: 33
      # 89000: 35 (18h)
    # - caffe train --solver="proto/solverPretrainConv.prototxt" --weights="snapshots/pretraining__iter_40000.caffemodel" > $PREFIX.step010_pretrainConv.txt 2>&1

    - caffe train --solver="proto/solverPretrainConvCifar10.prototxt" > $PREFIX.step000_pretrainConvCifar10.txt 2>&1
        # starting loss: as far as I remember, about 4.5/4.6
        # I0602 08:03:31.369220    10 solver.cpp:213] Iteration 6990, loss = 1.169
        # I0602 08:03:31.369253    10 solver.cpp:228]     Train net output #0: prob = 1.169 (* 1 = 1.169 loss)
        # I0602 08:03:31.369271    10 solver.cpp:473] Iteration 6990, lr = 0.0001
        # I0602 08:03:39.041399    10 solver.cpp:362] Snapshotting to snapshots/pretraining_conv_cifar10_iter_7000.caffemodel
        # I0602 08:03:39.043371    10 solver.cpp:370] Snapshotting solver state to snapshots/pretraining_conv_cifar10_iter_7000.solverstate
        # I0602 08:03:39.044637    10 solver.cpp:291] Iteration 7000, Testing net (#0)
        # I0602 08:03:56.600191    10 solver.cpp:342]     Test net output #0: accurLayerWinnerTop1 = 0.586693
        # I0602 08:03:56.600273    10 solver.cpp:342]     Test net output #1: accurLayerWinnerTop5 = 0.954293
        # I0602 08:03:56.600293    10 solver.cpp:342]     Test net output #2: prob = 1.16343 (* 1 = 1.16343 loss)
        # I0602 08:03:57.417232    10 solver.cpp:213] Iteration 7000, loss = 1.11132

    # - caffe train --solver="proto/solverPretrainConv.prototxt" --weights="snapshots/pretraining_conv_cifar10_iter_7000.caffemodel" > $PREFIX.step010_pretrainConv.txt 2>&1
    - caffe train --solver="proto/solverPretrainConv.prototxt" --weights="snapshots/pretraining_conv_cifar10_iter_40000.caffemodel" > $PREFIX.step010_pretrainConv.txt 2>&1
      # - caffe train --solver="proto/solverPretrainConv.prototxt" --snapshot="snapshots/pretraining_conv_iter_7000.solverstate" > $PREFIX.step011_solverPretrainConvCont.txt 2>&1 # just to go on for the week end
        # 8h from 7000 to 40000:
        # Iteration 39990, loss = 2.52498
        #     Train net output #0: prob = 2.52498 (* 1 = 2.52498 loss)
        # Iteration 39990, lr = 0.0001
        # Snapshotting to snapshots/pretraining_conv_iter_40000.caffemodel
        # Snapshotting solver state to snapshots/pretraining_conv_iter_40000.solverstate
        # Iteration 40000, loss = 2.73032
        # Iteration 40000, Testing net (#0)
        #     Test net output #0: accurLayerWinnerTop1 = 0.323333
        #     Test net output #1: accurLayerWinnerTop5 = 0.615893
        #     Test net output #2: prob = 2.76338 (* 1 = 2.76338 loss)
    # - BAD learning rate : caffe train --solver="proto/solverReconstructIncremental1.prototxt" --weights="snapshots/pretraining_conv_iter_40000.caffemodel" > $PREFIX.step020_reconstructInc1.txt 2>&1  # --iterations=2000
        # Nan :
        #   Iteration 0, Testing net (#0)
        #       Test net output #0: L2_loss = 4.07108e+08 (* 1 = 4.07108e+08 loss)
        #   Iteration 0, loss = 4.0589e+08
        #       Train net output #0: L2_loss = 4.0589e+08 (* 1 = 4.0589e+08 loss)
        #   Iteration 0, lr = 1e-07
        #   Iteration 5, loss = nan
      #       Train net output #0: L2_loss = nan (* 1 = nan loss)
    - caffe train --solver="proto/solverReconstructIncremental1v2.prototxt" --weights="snapshots/pretraining_conv_iter_40000.caffemodel" > $PREFIX.step020_reconstructInc1.txt 2>&1  # --iterations=2000
        # Iteration 0, Testing net (#0)
        #     Test net output #0: L2_loss = 4.07729e+08 (* 1 = 4.07729e+08 loss)
        # Iteration 0, loss = 4.06565e+08
        #     Train net output #0: L2_loss = 4.06565e+08 (* 1 = 4.06565e+08 loss)
        # Iteration 0, lr = 5e-10
        # ...
        # Iteration 1995, loss = 1.25529e+07
        #     Train net output #0: L2_loss = 1.25529e+07 (* 1 = 1.25529e+07 loss)
        # Iteration 1995, lr = 5e-10
        # Snapshotting to snapshots/reconstructing_incremental_1_iter_2000.caffemodel
        # Snapshotting solver state to snapshots/reconstructing_incremental_1_iter_2000.solverstate
        # Iteration 2000, loss = 1.2672e+07
        # Iteration 2000, Testing net (#0)
        #     Test net output #0: L2_loss = 1.29921e+07 (* 1 = 1.29921e+07 loss)
    - caffe train --solver="proto/solverReconstructIncremental2v2.prototxt" --weights="snapshots/reconstructing_incremental_1_iter_2000.caffemodel"  > $PREFIX.step030_reconstructInc2.txt 2>&1  #  --iterations=2000
        # Iteration 0, Testing net (#0)
        #     Test net output #0: L2_loss = 2.1654e+08 (* 1 = 2.1654e+08 loss)
        # Iteration 0, loss = 2.15841e+08
        #     Train net output #0: L2_loss = 2.15841e+08 (* 1 = 2.15841e+08 loss)
        # Iteration 0, lr = 5e-10
        # ...
        # Iteration 1995, loss = 5.96489e+06
        #     Train net output #0: L2_loss = 5.96489e+06 (* 1 = 5.96489e+06 loss)
        # Iteration 1995, lr = 5e-10
        # Snapshotting to snapshots/reconstructing_incremental_2_iter_2000.caffemodel
        # Snapshotting solver state to snapshots/reconstructing_incremental_2_iter_2000.solverstate
        # Iteration 2000, loss = 6.0563e+06
        # Iteration 2000, Testing net (#0)
        #     Test net output #0: L2_loss = 6.17771e+06 (* 1 = 6.17771e+06 loss)
    - caffe train --solver="proto/solverReconstructFull.prototxt" --weights="snapshots/reconstructing_incremental_2_iter_2000.caffemodel"  > $PREFIX.step040_recontructFull.txt 2>&1 # --iterations=15000
    - caffe train --solver="proto/solverReconstructFull_FC0.prototxt" --weights="snapshots/reconstructing_full_extra_iter_15000.caffemodel"  > $PREFIX.step050_reconstructFullFC0.txt 2>&1 # --iterations=30000
    - caffe test  --model=proto/reconstructFull_FC0.prototxt --weights=snapshots/reconstructing_full_extra_FC0_iter_30000.caffemodel  > $PREFIX.step060_test.txt 2>&1 # --iterations=50
  download:
    usage: download caffe
    container_working_directory: /opt/
    actions:
    - git clone https://github.com/matthieudelaro/caffeBVLCplus.git caffe
    - cd caffe
    - cp Makefile.config.example Makefile.config
  download-old:
    usage: download caffe
    container_working_directory: /opt/
    actions:
    - git clone https://github.com/matthieudelaro/caffe.git caffe
    - cd caffe
    - cp Makefile.config.example Makefile.config
  build:
    usage: build the project
    actions:
    - make all -j8
    - echo "/opt/caffe/.build_release/lib/" >> /etc/ld.so.conf.d/caffe-ld-so.conf
    - ldconfig
  build-cpu:
    usage: build the project in CPU mode only (set CPU_ONLY from Makefile.config on the fly)
    actions:
    - make all -j8
    - echo "/opt/caffe/.build_release/lib/" >> /etc/ld.so.conf.d/caffe-ld-so.conf
    - ldconfig
  build-gpu:
    usage: build the project in GPU mode (unset CPU_ONLY from Makefile.config on the fly)
    actions:
    - sed -i 's/CPU_ONLY := 1/# CPU_ONLY := 1/' Makefile.config
    # - sed -i 's/# USE_CUDNN := 1/USE_CUDNN := 1/' Makefile.config
    - make all -j8
    - echo "/opt/caffe/.build_release/lib/" >> /etc/ld.so.conf.d/caffe-ld-so.conf
    - ldconfig
  build-pycaffe:
    usage: build pycaffe
    actions:
    - make pycaffe -j8
  test-cpu:
    usage: run the tests in CPU mode only (set CPU_ONLY from Makefile.config on the fly)
    actions:
    - sed -i 's/# CPU_ONLY := 1/CPU_ONLY := 1/' Makefile.config
    - make runtest -j8
  test-gpu:
    usage: run the tests in GPU mode (unset CPU_ONLY from Makefile.config on the fly)
    enable_nvidia_devices: true
    actions:
    - sed -i 's/CPU_ONLY := 1/# CPU_ONLY := 1/' Makefile.config
    # - sed -i 's/# USE_CUDNN := 1/USE_CUDNN := 1/' Makefile.config
    - make runtest -j8
  train-mnist-cpu:
    usage: attemps to train MNIST in CPU mode only (solver_mode in examples/mnist/lenet_solver.prototxt on the fly)
    actions:
    - "sed -i 's/solver_mode: GPU/solver_mode: CPU/' examples/mnist/lenet_solver.prototxt"
    - ./data/mnist/get_mnist.sh
    - ./examples/mnist/create_mnist.sh
    - caffe train --solver=examples/mnist/lenet_solver.prototxt
  train-mnist-gpu:
    usage: attemps to train MNIST in GPU mode (solver_mode in examples/mnist/lenet_solver.prototxt on the fly)
    enable_nvidia_devices: true
    actions:
    # - "sed -i 's/solver_mode: CPU/solver_mode: GPU/' examples/mnist/lenet_solver.prototxt"
    # - ./data/mnist/get_mnist.sh
    # - ./examples/mnist/create_mnist.sh
    - caffe train --solver=examples/mnist/lenet_solver.prototxt

